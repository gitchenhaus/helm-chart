USER-SUPPLIED VALUES:
additionalPrometheusRulesMap:
  rule-name:
    groups:
    - name: scrapeJobCheck
      rules:
      - alert: scrapeDown
        annotations:
          message: Scrape 異常 - {{ $labels.instance }} 服務異常.
        expr: |
          up{job!="coredns"}  == 0
        for: 1m
        labels:
          service: Scrape
          severity: critical
    - name: kubernetesgroup
      rules:
      - alert: KubeAPIDown
        annotations:
          message: 異常 - 體彩產品 KubeApi 出現異常.
        expr: |
          absent(up{job="apiserver"} == 1)
        for: 5m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesNodeReady
        annotations:
          description: |-
            Node {{ $labels.node }} has been unready for a long time
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes Node ready (instance {{ $labels.instance }})
        expr: |
          kube_node_status_condition{condition="Ready",status="true"} == 0
        for: 10m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesMemoryPressure
        annotations:
          description: |-
            {{ $labels.node }} has MemoryPressure condition
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes memory pressure (instance {{ $labels.instance }})
        expr: |
          kube_node_status_condition{condition="MemoryPressure",status="true"} == 1
        for: 2m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesDiskPressure
        annotations:
          description: |-
            {{ $labels.node }} has DiskPressure condition
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes disk pressure (instance {{ $labels.instance }})
        expr: |
          kube_node_status_condition{condition="DiskPressure",status="true"} == 1
        for: 2m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesOutOfDisk
        annotations:
          description: |-
            {{ $labels.node }} has OutOfDisk condition
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes out of disk (instance {{ $labels.instance }})
        expr: |
          kube_node_status_condition{condition="OutOfDisk",status="true"} == 1
        for: 2m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesOutOfCapacity
        annotations:
          description: |-
            {{ $labels.node }} is out of capacity
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes out of capacity (instance {{ $labels.instance }})
        expr: |
          sum by (node) ((kube_pod_status_phase{phase="Running"} == 1) + on(uid) group_left(node) (0 * kube_pod_info{pod_template_hash=""})) / sum by (node) (kube_node_status_allocatable{resource="pods"}) * 100 > 90
        for: 2m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesContainerOomKiller
        annotations:
          description: |-
            Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} has been OOMKilled {{ $value }} times in the last 10 minutes.
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes container oom killer (instance {{ $labels.instance }})
        expr: |
          (kube_pod_container_status_restarts_total - kube_pod_container_status_restarts_total offset 10m >= 1) and ignoring (reason) min_over_time(kube_pod_container_status_last_terminated_reason{reason="OOMKilled"}[10m]) == 1
        for: 0m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesJobFailed
        annotations:
          description: |-
            Job {{$labels.namespace}}/{{$labels.exported_job}} failed to complete
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes Job failed (instance {{ $labels.instance }})
        expr: |
          kube_job_status_failed > 0
        for: 0m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesPersistentvolumeclaimPending
        annotations:
          description: |-
            PersistentVolumeClaim {{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is pending
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes PersistentVolumeClaim pending (instance {{ $labels.instance
            }})
        expr: |
          kube_persistentvolumeclaim_status_phase{phase="Pending"} == 1
        for: 2m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesVolumeOutOfDiskSpace
        annotations:
          description: |-
            Volume is almost full (< 10% left)
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes Volume out of disk space (instance {{ $labels.instance
            }})
        expr: |
          kubelet_volume_stats_available_bytes / kubelet_volume_stats_capacity_bytes * 100 < 10
        for: 2m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesPersistentvolumeError
        annotations:
          description: |-
            Persistent volume is in bad state
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes PersistentVolume error (instance {{ $labels.instance
            }})
        expr: |
          kube_persistentvolume_status_phase{phase=~"Failed|Pending", job="kube-state-metrics"} > 0
        for: 0m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesStatefulsetDown
        annotations:
          description: |-
            A StatefulSet went down
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes StatefulSet down (instance {{ $labels.instance }})
        expr: |
          (kube_statefulset_status_replicas_ready / kube_statefulset_status_replicas_current) != 1
        for: 1m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesHpaScalingAbility
        annotations:
          description: |-
            Pod is unable to scale
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes HPA scaling ability (instance {{ $labels.instance }})
        expr: |
          kube_horizontalpodautoscaler_status_condition{status="false", condition="AbleToScale"} == 1
        for: 2m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesHpaMetricAvailability
        annotations:
          description: |-
            HPA is not able to collect metrics
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes HPA metric availability (instance {{ $labels.instance
            }})
        expr: |
          kube_horizontalpodautoscaler_status_condition{status="false", condition="ScalingActive"} == 1
        for: 0m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesHpaScaleCapability
        annotations:
          description: |-
            The maximum number of desired Pods has been hit
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes HPA scale capability (instance {{ $labels.instance }})
        expr: |
          kube_horizontalpodautoscaler_status_desired_replicas >= kube_horizontalpodautoscaler_spec_max_replicas
        for: 2m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesPodCrashLooping
        annotations:
          description: |-
            Pod {{ $labels.pod }} is crash looping
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes pod crash looping (instance {{ $labels.instance }})
        expr: |
          increase(kube_pod_container_status_restarts_total[1m]) > 3
        for: 2m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesReplicassetMismatch
        annotations:
          description: |-
            Deployment Replicas mismatch
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes ReplicasSet mismatch (instance {{ $labels.instance }})
        expr: |
          kube_replicaset_spec_replicas != kube_replicaset_status_ready_replicas
        for: 10m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesDeploymentReplicasMismatch
        annotations:
          description: |-
            Deployment Replicas mismatch
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes Deployment replicas mismatch (instance {{ $labels.instance
            }})
        expr: |
          kube_deployment_spec_replicas != kube_deployment_status_replicas_available
        for: 10m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesStatefulsetReplicasMismatch
        annotations:
          description: |-
            A StatefulSet does not match the expected number of replicas.
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes StatefulSet replicas mismatch (instance {{ $labels.instance
            }})
        expr: |
          kube_statefulset_status_replicas_ready != kube_statefulset_status_replicas
        for: 10m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesDeploymentGenerationMismatch
        annotations:
          description: |-
            A Deployment has failed but has not been rolled back.
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes Deployment generation mismatch (instance {{ $labels.instance }})
        expr: |
          kube_deployment_status_observed_generation != kube_deployment_metadata_generation
        for: 10m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesStatefulsetGenerationMismatch
        annotations:
          description: |-
            A StatefulSet has failed but has not been rolled back.
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes StatefulSet generation mismatch (instance {{ $labels.instance }})
        expr: |
          kube_statefulset_status_observed_generation != kube_statefulset_metadata_generation
        for: 10m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesStatefulsetUpdateNotRolledOut
        annotations:
          description: |-
            StatefulSet update has not been rolled out.
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes StatefulSet update not rolled out (instance {{ $labels.instance }})
        expr: |
          max without (revision) (kube_statefulset_status_current_revision unless kube_statefulset_status_update_revision) * (kube_statefulset_replicas != kube_statefulset_status_replicas_updated)
        for: 10m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesDaemonsetRolloutStuck
        annotations:
          description: |-
            Some Pods of DaemonSet are not scheduled or not ready
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes DaemonSet rollout stuck (instance {{ $labels.instance }})
        expr: |
          kube_daemonset_status_number_ready / kube_daemonset_status_desired_number_scheduled * 100 < 100 or kube_daemonset_status_desired_number_scheduled - kube_daemonset_status_current_number_scheduled > 0
        for: 10m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesDaemonsetMisscheduled
        annotations:
          description: |-
            Some DaemonSet Pods are running where they are not supposed to run
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes DaemonSet misscheduled (instance {{ $labels.instance }})
        expr: |
          kube_daemonset_status_number_misscheduled > 0
        for: 1m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesApiServerErrors
        annotations:
          description: |-
            Kubernetes API server is experiencing high error rate
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes API server errors (instance {{ $labels.instance }})
        expr: |
          sum(rate(apiserver_request_total{job="apiserver",code=~"^(?:5..)$"}[1m])) / sum(rate(apiserver_request_total{job="apiserver"}[1m])) * 100 > 3
        for: 2m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesApiClientErrors
        annotations:
          description: |-
            Kubernetes API client is experiencing high error rate
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes API client errors (instance {{ $labels.instance }})
        expr: |
          (sum(rate(rest_client_requests_total{code=~"(4|5).."}[1m])) by (instance, job) / sum(rate(rest_client_requests_total[1m])) by (instance, job)) * 100 > 1
        for: 2m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesClientCertificateExpiresNextWeek
        annotations:
          description: |-
            A client certificate used to authenticate to the apiserver is expiring next week.
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes client certificate expires next week (instance {{ $labels.instance }})
        expr: |
          apiserver_client_certificate_expiration_seconds_count{job="apiserver"} > 0 and histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 7*24*60*60
        for: 0m
        labels:
          service: Kubernetes
          severity: critical
      - alert: KubernetesClientCertificateExpiresSoon
        annotations:
          description: |-
            A client certificate used to authenticate to the apiserver is expiring in less than 24.0 hours.
              VALUE = {{ $value }}
              LABELS = {{ $labels }}
          summary: Kubernetes client certificate expires soon (instance {{ $labels.instance
            }})
        expr: |
          apiserver_client_certificate_expiration_seconds_count{job="apiserver"} > 0 and histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 24*60*60
        for: 0m
        labels:
          service: Kubernetes
          severity: critical
    - name: storagegroup
      rules:
      - alert: MysqlDown
        annotations:
          message: 異常 - {{ $labels.instance }} 停止服務.
        expr: |
          mysql_up == 0
        for: 1m
        labels:
          service: MySQL
          severity: critical
      - alert: MysqlRestarted
        annotations:
          message: 異常 - {{ $labels.instance }} 服務重啟.
        expr: |
          mysql_global_status_uptime < 60
        for: 1m
        labels:
          service: MySQL
          severity: critical
      - alert: MySQL Connection>3200(80%)
        annotations:
          message: 異常 - 體彩產品伺服器出現MySQL連線數使用過高的情況大於80%
        expr: |
          mysql_global_status_max_used_connections{namespace=~"monitor"} > 3200
        for: 30m
        labels:
          service: MySQL
          severity: critical
      - alert: MySQL Connection>=2800(70%),<3200(80%)
        annotations:
          message: 警告 - 體彩產品伺服器出現MySQL連線數使用過高的情況大於70%,小於80%,請收集相關資訊,並於下一個工作日提供給體彩SRE人員
        expr: |
          mysql_global_status_max_used_connections{namespace=~"monitor"} >= 2800 and mysql_global_status_max_used_connections{namespace=~"monitor"} <= 3200
        for: 30m
        labels:
          service: MySQL
          severity: critical
      - alert: MongoDB Connection>12800(80%)
        annotations:
          message: 異常 - 體彩產品伺服器出現MongoDB連線數使用過高的情況大於80%
        expr: |
          mongodb_connections{namespace="monitor",state="current"} > 12800
        for: 30m
        labels:
          service: MongoDB
          severity: critical
      - alert: MongoDB Connection>=11200(70%),<12800(80%)
        annotations:
          message: 警告 - 體彩產品伺服器出現MongoDB連線數使用過高的情況大於70%,小於80%,請收集相關資訊,並於下一個工作日提供給體彩SRE人員
        expr: |
          mongodb_connections{namespace="monitor",state="current"} >= 11200 and mongodb_connections{namespace="monitor",state="current"} <= 12800
        for: 30m
        labels:
          service: MongoDB
          severity: critical
      - alert: KafkaTopicsReplicas
        annotations:
          message: 異常 - 體彩產品Kafka Cluster服務出現異常, Partitions Per Topic 數量不一致
        expr: |
          sum(kafka_topic_partition_in_sync_replica) by (topic) < 27
        for: 0m
        labels:
          service: Kafka
          severity: critical
      - alert: KafkaDown
        annotations:
          message: 異常 - {{ $labels.instance }} 停止服務.
        expr: kafka_brokers < kafka_brokers offset 1m
        labels:
          service: Kafka
          severity: critical
      - alert: KafkaRestart
        annotations:
          message: 異常 - {{ $labels.instance }} 服務重啟.
        expr: process_start_time_seconds < process_start_time_seconds offset 1m
        labels:
          service: Kafka
          severity: critical
      - alert: MongoDown
        annotations:
          message: 異常 - {{ $labels.instance }} 停止服務.
        expr: mongodb_up == 0
        for: 1m
        labels:
          service: MongoDB
          severity: critical
      - alert: MongoRestart
        annotations:
          message: 異常 - {{ $labels.instance }} 服務重啟.
        expr: mongodb_instance_uptime_seconds <= mongodb_instance_uptime_seconds offset
          1m
        for: 1m
        labels:
          service: MongoDB
          severity: critical
      - alert: RedisDown
        annotations:
          message: 異常 - {{ $labels.instance }} 停止服務.
        expr: redis_up == 0
        for: 0m
        labels:
          service: Redis
          severity: critical
      - alert: RedisRestart
        annotations:
          message: 異常 - {{ $labels.instance }} 服務重啟.
        expr: redis_uptime_in_seconds <= redis_uptime_in_seconds offset 1m
        for: 1m
        labels:
          service: Redis
          severity: critical
      - alert: RabbitMQDown
        annotations:
          message: 異常 - {{ $labels.instance }} 停止服務.
        expr: rabbitmq_up == 0
        for: 0m
        labels:
          service: RabbitMQ
          severity: critical
      - alert: RabbitMQRestart
        annotations:
          message: 異常 - {{ $labels.instance }} 服務重啟.
        expr: rabbitmq_erlang_uptime_seconds <= rabbitmq_erlang_uptime_seconds offset
          1m
        for: 1m
        labels:
          service: RabbitMQ
          severity: critical
    - name: basic_metrics
      rules:
      - alert: CPU Usage Over 70%
        annotations:
          description: CPU Usage of {{$labels.nodeInfo}} has been over 70% for more
            than 1m.
          summary: CPU Usage Over 70 % (`{{ $labels.nodeInfo }}`/`{{$value}}%`)
        expr: (1 - avg(irate(node_cpu_seconds_total{job=~"node-.*",mode="idle"}[5m]))
          by (nodeInfo))* 100 > 70
        for: 1m
        labels:
          environment: prod
          severity: warning
          type: cpu
      - alert: CPU Usage Over 85%
        annotations:
          description: CPU Usage of {{$labels.nodeInfo}} has been over 85% for more
            than 1m.
          summary: CPU Usage Over 85 % (`{{ $labels.nodeInfo }}`/`{{$value}}%`)
        expr: (1 - avg(irate(node_cpu_seconds_total{job=~"node-.*",mode="idle"}[5m]))
          by (nodeInfo))* 100 > 85
        for: 1m
        labels:
          environment: prod
          severity: critical
          type: cpu
      - alert: Memory Usage Over 70%
        annotations:
          description: Memory Usage of {{$labels.nodeInfo}} has been over 70% for
            more than 1m.
          summary: Memory Usage Over 70% (`{{ $labels.nodeInfo }}`/`{{$value}}%`)
        expr: (1 - (node_memory_MemAvailable_bytes{job=~"node-.*"} / (node_memory_MemTotal_bytes{job=~"node-.*"})))*
          100 > 70
        for: 1m
        labels:
          environment: prod
          severity: warning
          type: memory
      - alert: Memory Usage Over 85%
        annotations:
          description: Memory Usage of {{$labels.nodeInfo}} has been over 85% for
            more than 1m.
          summary: Memory Usage Over 85% (`{{ $labels.nodeInfo }}`/`{{$value}}%`)
        expr: (1 - (node_memory_MemAvailable_bytes{job=~"node-.*"} / (node_memory_MemTotal_bytes{job=~"node-.*"})))*
          100 > 85
        for: 1m
        labels:
          environment: prod
          severity: critical
          type: memory
      - alert: Disk Usage Over 70%
        annotations:
          description: Disk Usage of {{$labels.nodeInfo}} has been over 70% for more
            than 1m.
          summary: Disk Usage Over 70% (`{{ $labels.nodeInfo }}`/`{{$value}}%`)
        expr: max((node_filesystem_size_bytes{job=~"node-.*",fstype=~"ext.?|xfs"}-node_filesystem_free_bytes{job=~"node-.*",fstype=~"ext.?|xfs"})
          *100/(node_filesystem_avail_bytes {job=~"node-.*",fstype=~"ext.?|xfs"}+(node_filesystem_size_bytes{job=~"node-.*",fstype=~"ext.?|xfs"}-node_filesystem_free_bytes{job=~"node-.*",fstype=~"ext.?|xfs"})))by(nodeInfo)
          > 70
        for: 1m
        labels:
          environment: prod
          severity: warning
          type: disk
      - alert: Disk Usage Over 85%
        annotations:
          description: Disk Usage of {{$labels.nodeInfo}} has been over 85% for more
            than 1m.
          summary: Disk Usage Over 85% (`{{ $labels.nodeInfo }}`/`{{$value}}%`)
        expr: max((node_filesystem_size_bytes{job=~"node-.*",fstype=~"ext.?|xfs"}-node_filesystem_free_bytes{job=~"node-.*",fstype=~"ext.?|xfs"})
          *100/(node_filesystem_avail_bytes {job=~"node-.*",fstype=~"ext.?|xfs"}+(node_filesystem_size_bytes{job=~"node-.*",fstype=~"ext.?|xfs"}-node_filesystem_free_bytes{job=~"node-.*",fstype=~"ext.?|xfs"})))by(nodeInfo)
          > 85
        for: 1m
        labels:
          environment: prod
          severity: critical
          type: disk

alertmanager:
  enabled: true
  config:
    global:
      opsgenie_api_key: ""
      resolve_timeout: 1m
    receivers:
    - name: 'null'
    - name: general-slack
      slack_configs:
      - api_url: https://hooks.slack.com/services/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
        channel: null
        icon_url: https://avatars3.githubusercontent.com/u/3380462
        send_resolved: true
        title_link: http://dev.env.sb.rexbet.com:30800
        username: alerter
    route:
      receiver: "null"
      group_by:
      - severity
      group_wait: 5s
      group_interval: 1s
      repeat_interval: 1m  
      routes:
      - receiver: general-slack
        match:
          severity: critical
        group_by:
        - instance
        group_interval: 10m
        group_wait: 5s
        repeat_interval: 1m
        
  service:
    nodePort: 30093
    type: NodePort
defaultRules:
  create: true
  rules:
    alertmanager: false
    etcd: false
    general: false
    k8s: true
    kubeApiserver: true
    kubeApiserverAvailability: true
    kubeApiserverError: false
    kubeApiserverSlos: false
    kubePrometheusGeneral: true
    kubePrometheusNodeAlerting: false
    kubePrometheusNodeRecording: true
    kubeScheduler: true
    kubeStateMetrics: false
    kubelet: true
    kubernetesAbsent: false
    kubernetesApps: false
    kubernetesResources: false
    kubernetesStorage: false
    kubernetesSystem: false
    network: false
    node: true
    prometheus: false
    prometheusOperator: false
    time: false
grafana:
  adminPassword: '!QAZ3edc%TGB'
  enabled: true
  env:
    GF_SERVER_ROOT_URL: '%(protocol)s://%(domain)s/'
  plugins:
  - grafana-piechart-panel
  replicas: 1
  service:
    nodePort: 31874
    type: NodePort
kubeControllerManager:
  enabled: false
kubeEtcd:
  enabled: false
kubeProxy:
  enabled: false
kubeScheduler:
  enabled: false
nodeExporter:
  enabled: true
  serviceMonitor:
    relabelings:
    - action: replace
      regex: ^(.*)$
      replacement: $1
      separator: ;
      sourceLabels:
      - __meta_kubernetes_pod_node_name
      targetLabel: nodeInfo
prometheus:
  prometheusSpec:
    containers:
    - env:
      - name: JAEGER_AGENT_PORT
        value: "5755"
      name: prometheus
    remoteWriteDashboards: true
    resources:
      limits:
        memory: 1Gi
    storageSpec:
      volumeClaimTemplate:
        spec:
          accessModes:
          - ReadWriteOnce
          resources:
            requests:
              storage: 5Gi
          storageClassName: standard
  service:
    nodePort: 30090
    type: NodePort
prometheusOperator:
  enabled: true